{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wisconsin import data, baseline, model, optimise\n",
    "from typing import List\n",
    "import plotly.express as px\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.download(unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = baseline.load_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de44087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    run_name: str,\n",
    "    df: pd.DataFrame,\n",
    "    model_types: List[str] = [\"random_forest\", \"logistic_regression\", \"svm\", \"xgboost\", \"neural_network\", \"lightgbm\"],\n",
    "    n_splits=5\n",
    "):\n",
    "    results = []\n",
    "\n",
    "    for model_type in model_types:\n",
    "        print(f\"{model_type}...\")\n",
    "        result = model.cross_validate_model(df, model_type, n_splits=n_splits)\n",
    "        results.append(result)\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    acc_pr_df = results_df[['model', 'accuracy_min', 'accuracy_mean', 'accuracy_max', 'precision_min', 'precision_mean', 'precision_max']].copy()\n",
    "    acc_pr_df.rename(columns={\"accuracy_mean\": \"accuracy_avg\", \"precision_mean\": \"precision_avg\"}, inplace=True)\n",
    "    acc_pr_df[[\"accuracy_min\",\"accuracy_avg\",\"accuracy_max\",\"precision_min\",\"precision_avg\",\"precision_max\"]] *= 100\n",
    "    acc_pr_df['model_type'] = run_name\n",
    "\n",
    "    acc_pr_df.replace(\n",
    "        {\n",
    "            \"random_forest\" : \"random_forest_classification\",\n",
    "            \"xgboost\": \"xgboost_classification\",\n",
    "            \"svm\": \"support_vector_classification\",\n",
    "            \"neural_network\": \"neural_network_classification\"\n",
    "        }, inplace=True\n",
    "    )\n",
    "\n",
    "    return results_df, acc_pr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_colors(n, cmap_name='nipy_spectral'):\n",
    "    cmap = plt.cm.get_cmap(cmap_name, n)\n",
    "    return [f'rgb({int(r*255)},{int(g*255)},{int(b*255)})'\n",
    "            for r, g, b, _ in cmap(np.linspace(0, 1, n))]\n",
    "\n",
    "def precision_plot(dfs: List[pd.DataFrame], height=None, more_colours=False):\n",
    "    \n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    model_order = df['model'].unique()\n",
    "    model_map = {model: i for i, model in enumerate(model_order)}\n",
    "    df['y_numeric'] = df['model'].map(model_map).astype(float)\n",
    "\n",
    "    jitter_strength = 0.2\n",
    "    jitter = df['model_type'].astype('category').cat.codes * jitter_strength\n",
    "    df['y_jittered'] = df['y_numeric'] + jitter\n",
    "\n",
    "    unique_models = df['model_type'].nunique()\n",
    "    \n",
    "    if more_colours:\n",
    "        color_list = get_n_colors(unique_models)\n",
    "    else:\n",
    "        color_list = px.colors.qualitative.Plotly\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x='precision_avg',\n",
    "        y='y_jittered',\n",
    "        color='model_type',\n",
    "        error_x=df['precision_max'] - df['precision_avg'],\n",
    "        error_x_minus=df['precision_avg'] - df['precision_min'],\n",
    "        labels={'precision_avg': 'Precision (%)'},\n",
    "        title='Precision',\n",
    "        template='plotly_white',\n",
    "        size_max=10,\n",
    "        color_discrete_sequence=color_list,\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker=dict(size=10))\n",
    "    fig.update_yaxes(\n",
    "        tickvals=list(model_map.values()),\n",
    "        ticktext=list(model_map.keys()),\n",
    "        title='Model'\n",
    "    )\n",
    "    if height:\n",
    "        fig.update_layout(\n",
    "            height=height,\n",
    "        )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def accuracy_plot(dfs: List[pd.DataFrame], height=None, more_colours=False):\n",
    "    \n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    model_order = df['model'].unique()\n",
    "    model_map = {model: i for i, model in enumerate(model_order)}\n",
    "    df['y_numeric'] = df['model'].map(model_map).astype(float)\n",
    "\n",
    "    jitter_strength = 0.2\n",
    "    jitter = df['model_type'].astype('category').cat.codes * jitter_strength\n",
    "    df['y_jittered'] = df['y_numeric'] + jitter\n",
    "\n",
    "    unique_models = df['model_type'].nunique()\n",
    "\n",
    "\n",
    "    if more_colours:\n",
    "        color_list = get_n_colors(unique_models)\n",
    "    else:\n",
    "        color_list = px.colors.qualitative.Plotly\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x='accuracy_avg',\n",
    "        y='y_jittered',\n",
    "        color='model_type',\n",
    "        error_x=df['accuracy_max'] - df['accuracy_avg'],\n",
    "        error_x_minus=df['accuracy_avg'] - df['accuracy_min'],\n",
    "        labels={'accuracy_avg': 'Accuracy (%)'},\n",
    "        title='Accuracy',\n",
    "        template='plotly_white',\n",
    "        size_max=10,\n",
    "        color_discrete_sequence=color_list,\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker=dict(size=10))\n",
    "    fig.update_yaxes(\n",
    "        tickvals=list(model_map.values()),\n",
    "        ticktext=list(model_map.keys()),\n",
    "        title='Model'\n",
    "    )\n",
    "    if height:\n",
    "        fig.update_layout(\n",
    "            height=height,\n",
    "        )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6257636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(df):\n",
    "    models = df[\"model\"].tolist()\n",
    "    fig = make_subplots(rows=3, cols=2, subplot_titles=models)\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        roc_data = row[\"roc_data\"]\n",
    "        model_name = row[\"model\"]\n",
    "\n",
    "        row_num = i // 2 + 1\n",
    "        col_num = i % 2 + 1\n",
    "\n",
    "        for fold_data in roc_data:\n",
    "            fpr = fold_data[\"fpr\"]\n",
    "            tpr = fold_data[\"tpr\"]\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=fpr,\n",
    "                    y=tpr,\n",
    "                    mode=\"lines\",\n",
    "                    name=f\"{model_name} - fold {fold_data['fold']}\",\n",
    "                    showlegend=False,\n",
    "                    line=dict(width=1)\n",
    "                ),\n",
    "                row=row_num,\n",
    "                col=col_num,\n",
    "            )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[0, 1],\n",
    "                y=[0, 1],\n",
    "                mode=\"lines\",\n",
    "                line=dict(dash=\"dash\", color=\"gray\"),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=row_num,\n",
    "            col=col_num,\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=900,\n",
    "        width=800,\n",
    "        title_text=\"ROC Curves per Model\",\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(title_text=\"False Positive Rate\")\n",
    "    fig.update_yaxes(title_text=\"True Positive Rate\")\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658b3c6",
   "metadata": {},
   "source": [
    "## Rebuild Baseline Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_plot([baseline_df])\n",
    "accuracy_plot([baseline_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854f6c0",
   "metadata": {},
   "source": [
    "## Default models\n",
    "\n",
    "Try emulating baseline models with 5-fold cross validation and default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_df, default_acc_pr_df = train(run_name=\"default\", df=df)\n",
    "precision_plot([baseline_df, default_acc_pr_df])\n",
    "accuracy_plot([baseline_df, default_acc_pr_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55908a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curves(default_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fdacc",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036dbd3c",
   "metadata": {},
   "source": [
    "Compute Shapley values to analyse contribution of features to predictions.\n",
    "\n",
    "- refit model with whole data and random_forest model\n",
    "- compute and plot Shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495eadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.refit_model(df, model_name=\"random_forest\")\n",
    "\n",
    "X = df.drop(columns=[\"ID\", \"Diagnosis\"])\n",
    "\n",
    "explainer = shap.Explainer(m, X)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "shap_values_class1 = shap_values.values[:, :, 1]\n",
    "\n",
    "shap_values_class1_expl = shap.Explanation(\n",
    "    values=shap_values_class1,\n",
    "    base_values=shap_values.base_values[:, 1],\n",
    "    data=X,\n",
    "    feature_names=X.columns.tolist()\n",
    ")\n",
    "\n",
    "mean_abs_shap = np.abs(shap_values_class1).mean(axis=0)\n",
    "feature_names = X.columns\n",
    "\n",
    "shap_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Mean SHAP Value\": mean_abs_shap\n",
    "}).sort_values(by=\"Mean SHAP Value\", ascending=False)\n",
    "\n",
    "top_k = 10\n",
    "top_df = shap_df.iloc[:top_k].copy()\n",
    "\n",
    "if shap_df.shape[0] > top_k:\n",
    "    others_sum = shap_df.iloc[top_k:][\"Mean SHAP Value\"].sum()\n",
    "    other_row = pd.DataFrame([{\n",
    "        \"Feature\": \"All other features\",\n",
    "        \"Mean SHAP Value\": others_sum\n",
    "    }])\n",
    "    top_df = pd.concat([top_df, other_row], ignore_index=True)\n",
    "\n",
    "fig = px.bar(\n",
    "    top_df,\n",
    "    x=\"Mean SHAP Value\",\n",
    "    y=\"Feature\",\n",
    "    orientation=\"h\",\n",
    "    title=f\"Top {top_k} Features by Mean SHAP Value (with 'All other features')\",\n",
    "    labels={\"Mean SHAP Value\": \"Mean |SHAP value|\"},\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.update_layout(yaxis=dict(autorange=\"reversed\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dd1fc3",
   "metadata": {},
   "source": [
    "## Top 5 Features Model\n",
    "\n",
    "Try using only the top 5 features (for the RF model above) for building models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb35223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_df, top5_acc_pr_df = train(run_name=\"top_5_features\", df=df[[\"Diagnosis\",\"area3\", \"perimeter3\", \"concave_points3\", \"radius3\", \"concave_points1\"]])\n",
    "precision_plot([baseline_df, default_acc_pr_df, top5_acc_pr_df])\n",
    "accuracy_plot([baseline_df, default_acc_pr_df, top5_acc_pr_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curves(top5_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ca163",
   "metadata": {},
   "source": [
    "## Top 1 Features Model\n",
    "\n",
    "Try using only the top feature (for the RF model above) for building models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_df, top1_acc_pr_df = train(run_name=\"top_feature\", df=df[[\"Diagnosis\",\"area3\"]])\n",
    "precision_plot([baseline_df, default_acc_pr_df, top5_acc_pr_df, top1_acc_pr_df])\n",
    "accuracy_plot([baseline_df, default_acc_pr_df, top5_acc_pr_df, top1_acc_pr_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ad481",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curves(top1_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871d56e",
   "metadata": {},
   "source": [
    "## One Feature Only\n",
    "\n",
    "Neural network with just a single feature per run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3397cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_feat_acc_pr_dfs = [default_acc_pr_df[default_acc_pr_df[\"model\"] == \"neural_network_classification\"]] \n",
    "\n",
    "for feature in df.drop(columns=[\"ID\", \"Diagnosis\"]).columns:\n",
    "    print(feature)\n",
    "\n",
    "    feat_df, feat_acc_pr_df = train(run_name=f\"nn_{feature}\", df=df[['Diagnosis', feature]], model_types=[\"neural_network\"])\n",
    "    one_feat_acc_pr_dfs.append(feat_acc_pr_df)\n",
    "\n",
    "one_feat_acc_pr_df = pd.concat(one_feat_acc_pr_dfs)\n",
    "\n",
    "one_feat_acc_pr_df = one_feat_acc_pr_df.sort_values(by=\"precision_avg\")\n",
    "precision_plot([one_feat_acc_pr_df], height=800, more_colours=True)\n",
    "\n",
    "one_feat_acc_pr_df = one_feat_acc_pr_df.sort_values(by=\"accuracy_avg\")\n",
    "accuracy_plot([one_feat_acc_pr_df], height=800, more_colours=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b522fb9",
   "metadata": {},
   "source": [
    "## Regularisation Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df, lr_acc_pr_df = train(run_name=f\"regularisation_experiments\", df=df, model_types=[\"logistic_regression\", \"logistic_regression_l1\", \"logistic_regression_l2\",\"logistic_regression_elastic\"])\n",
    "\n",
    "precision_plot([baseline_df[baseline_df[\"model\"] == \"logistic_regression\"], lr_acc_pr_df])\n",
    "accuracy_plot([baseline_df[baseline_df[\"model\"] == \"logistic_regression\"], lr_acc_pr_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255a77b",
   "metadata": {},
   "source": [
    "## Single Feature Group Models\n",
    "\n",
    "Compare predictive power of individual feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca06efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_df, group1_acc_pr_df = train(run_name=\"feature_group1\", df=df[[c for c in df.columns if c[-1] == str(1) or c == \"Diagnosis\"]])\n",
    "group2_df, group2_acc_pr_df = train(run_name=\"feature_group2\", df=df[[c for c in df.columns if c[-1] == str(2) or c == \"Diagnosis\"]])\n",
    "group3_df, group3_acc_pr_df = train(run_name=\"feature_group3\", df=df[[c for c in df.columns if c[-1] == str(3) or c == \"Diagnosis\"]])\n",
    "\n",
    "precision_plot([default_acc_pr_df, group1_acc_pr_df, group2_acc_pr_df, group3_acc_pr_df])\n",
    "accuracy_plot([default_acc_pr_df, group1_acc_pr_df, group2_acc_pr_df, group3_acc_pr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curves(group1_df)\n",
    "plot_roc_curves(group2_df)\n",
    "plot_roc_curves(group3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d1b2b4",
   "metadata": {},
   "source": [
    "# Model without top 5 features\n",
    "\n",
    "In case top 5 features are leading to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f9777",
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_top5_df, minus_top5_acc_pr_df = train(run_name=\"without_top5\", df=df.drop(columns=[\"area3\", \"perimeter3\", \"concave_points3\", \"radius3\", \"concave_points1\"]))\n",
    "\n",
    "precision_plot([baseline_df, default_acc_pr_df, minus_top5_acc_pr_df])\n",
    "accuracy_plot([baseline_df, default_acc_pr_df, minus_top5_acc_pr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curves(minus_top5_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4aed4e",
   "metadata": {},
   "source": [
    "## Without top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0245525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_top10_df, minus_top10_acc_pr_df = train(run_name=\"without_top10\", df=df.drop(columns=[\n",
    "    \"area3\", \"perimeter3\", \"concave_points3\", \"radius3\", \"concave_points1\", \"concavity3\", \"area1\", \"area2\", \"concavity1\", \"texture3\"\n",
    "]))\n",
    "\n",
    "precision_plot([baseline_df, default_acc_pr_df, minus_top10_acc_pr_df])\n",
    "accuracy_plot([baseline_df, default_acc_pr_df, minus_top10_acc_pr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77959a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curves(minus_top10_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e85d5",
   "metadata": {},
   "source": [
    "## Optimise Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = optimise.run_optuna(df, \"random_forest\", n_trials=100, n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea768ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"opt\"\n",
    "rr = pd.DataFrame([{k: v for k, v in r.items() if k != \"params\"}])\n",
    "acc_pr_df = rr[['model', 'accuracy_min', 'accuracy_mean', 'accuracy_max', 'precision_min', 'precision_mean', 'precision_max']].copy()\n",
    "acc_pr_df.rename(columns={\"accuracy_mean\": \"accuracy_avg\", \"precision_mean\": \"precision_avg\"}, inplace=True)\n",
    "acc_pr_df[[\"accuracy_min\",\"accuracy_avg\",\"accuracy_max\",\"precision_min\",\"precision_avg\",\"precision_max\"]] *= 100\n",
    "acc_pr_df['model_type'] = run_name\n",
    "\n",
    "acc_pr_df.replace(\n",
    "    {\n",
    "        \"random_forest\" : \"random_forest_classification\",\n",
    "        \"xgboost\": \"xgboost_classification\",\n",
    "        \"svm\": \"support_vector_classification\",\n",
    "        \"neural_network\": \"neural_network_classification\"\n",
    "    }, inplace=True\n",
    ")\n",
    "\n",
    "accuracy_plot(\n",
    "    [\n",
    "        baseline_df[baseline_df['model'] == 'random_forest_classification'],\n",
    "        default_acc_pr_df[default_acc_pr_df['model'] == 'random_forest_classification'],\n",
    "        acc_pr_df[acc_pr_df['model'] == 'random_forest_classification']\n",
    "    ]\n",
    ")\n",
    "precision_plot(\n",
    "    [\n",
    "        baseline_df[baseline_df['model'] == 'random_forest_classification'],\n",
    "        default_acc_pr_df[default_acc_pr_df['model'] == 'random_forest_classification'],\n",
    "        acc_pr_df[acc_pr_df['model'] == 'random_forest_classification']\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6648b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = optimise.run_optuna(df, \"logistic_regression\", n_trials=200, n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"opt\"\n",
    "rr = pd.DataFrame([{k: v for k, v in r.items() if k != \"params\"}])\n",
    "acc_pr_df = rr[['model', 'accuracy_min', 'accuracy_mean', 'accuracy_max', 'precision_min', 'precision_mean', 'precision_max']].copy()\n",
    "acc_pr_df.rename(columns={\"accuracy_mean\": \"accuracy_avg\", \"precision_mean\": \"precision_avg\"}, inplace=True)\n",
    "acc_pr_df[[\"accuracy_min\",\"accuracy_avg\",\"accuracy_max\",\"precision_min\",\"precision_avg\",\"precision_max\"]] *= 100\n",
    "acc_pr_df['model_type'] = run_name\n",
    "\n",
    "acc_pr_df.replace(\n",
    "    {\n",
    "        \"random_forest\" : \"random_forest_classification\",\n",
    "        \"xgboost\": \"xgboost_classification\",\n",
    "        \"svm\": \"support_vector_classification\",\n",
    "        \"neural_network\": \"neural_network_classification\"\n",
    "    }, inplace=True\n",
    ")\n",
    "\n",
    "accuracy_plot(\n",
    "    [\n",
    "        baseline_df[baseline_df['model'] == 'logistic_regression'],\n",
    "        default_acc_pr_df[default_acc_pr_df['model'] == 'logistic_regression'],\n",
    "        acc_pr_df[acc_pr_df['model'] == 'logistic_regression']\n",
    "    ]\n",
    ")\n",
    "precision_plot(\n",
    "    [\n",
    "        baseline_df[baseline_df['model'] == 'logistic_regression'],\n",
    "        default_acc_pr_df[default_acc_pr_df['model'] == 'logistic_regression'],\n",
    "        acc_pr_df[acc_pr_df['model'] == 'logistic_regression']\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wisconsin-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
